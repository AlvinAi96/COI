{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 伪标签数据划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pse_label_df = pd.read_csv('../复赛融合/submit/sub_8223用于伪标签.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0003d01880444716a42159efe73d2c26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000dbfeed3594d5bb128a21c2078a786</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0010336c4cd44547852edd379487dbda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>001332737eaa443d85b6f59b07d28ed2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>00251d9b40164b638cc784d8e65df52f</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  label\n",
       "0  0003d01880444716a42159efe73d2c26      1\n",
       "1  000dbfeed3594d5bb128a21c2078a786      0\n",
       "2  0010336c4cd44547852edd379487dbda      1\n",
       "3  001332737eaa443d85b6f59b07d28ed2      1\n",
       "4  00251d9b40164b638cc784d8e65df52f      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pse_label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>b9dbbdee402e4dd0a5d1041ff44a001c</td>\n",
       "      <td>“两减六治三提升”专项督查暗访 常州溧阳：矿山生态修复滞后 企业防尘措施不到位</td>\n",
       "      <td>“两减六治三提升”专项督查暗访 常州溧阳：矿山生态修复滞后 企业防尘措施不到位</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1b48213241064f788dde3c3b359e7622</td>\n",
       "      <td>惊！南宁一家 4 口中毒，母亲口吐白沫！罪魁祸首竟是……</td>\n",
       "      <td>南宁晚报 /zaker 南宁记者 潘国武 文 / 图救援人员赶到邕武路二塘坡时，报警电话却无...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>f68215c26fed430dab72dd6bea7b52ad</td>\n",
       "      <td>病家求医寄以生死 丹阳人民医院枉为医表</td>\n",
       "      <td>本帖最后由 banished 于 2017-9-28 08:46 编辑 病家求医寄以生死 丹...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id                                    title  \\\n",
       "0  b9dbbdee402e4dd0a5d1041ff44a001c  “两减六治三提升”专项督查暗访 常州溧阳：矿山生态修复滞后 企业防尘措施不到位   \n",
       "1  1b48213241064f788dde3c3b359e7622             惊！南宁一家 4 口中毒，母亲口吐白沫！罪魁祸首竟是……   \n",
       "2  f68215c26fed430dab72dd6bea7b52ad                      病家求医寄以生死 丹阳人民医院枉为医表   \n",
       "\n",
       "                                             content  \n",
       "0            “两减六治三提升”专项督查暗访 常州溧阳：矿山生态修复滞后 企业防尘措施不到位  \n",
       "1  南宁晚报 /zaker 南宁记者 潘国武 文 / 图救援人员赶到邕武路二塘坡时，报警电话却无...  \n",
       "2  本帖最后由 banished 于 2017-9-28 08:46 编辑 病家求医寄以生死 丹...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('all_test.csv')\n",
    "test_df = test_df.loc[:,['id','title','content']]\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train(train_df, train_label_df):\n",
    "    random.seed(42)\n",
    "    split_num = 10\n",
    "    train_df=train_df.merge(train_label_df,on='id',how='left')\n",
    "    train_df['label']=train_df['label'].fillna(-1)\n",
    "    train_df=train_df[train_df['label']!=-1]\n",
    "    train_df['label']=train_df['label'].astype(int)\n",
    "    train_df['content']=train_df['content'].fillna('无')\n",
    "    train_df['title']=train_df['title'].fillna('无')\n",
    "    \n",
    "    index=set(range(train_df.shape[0]))\n",
    "    K_fold=[]\n",
    "    for i in range(split_num):\n",
    "        if i == split_num-1:\n",
    "            tmp=index\n",
    "        else:\n",
    "            tmp=random.sample(index,int(1.0/split_num*train_df.shape[0]))\n",
    "        index=index-set(tmp)\n",
    "        print(\"Number:\",len(tmp))\n",
    "        K_fold.append(tmp)\n",
    "\n",
    "\n",
    "    for i in range(split_num):\n",
    "        print(\"Fold\",i)\n",
    "        data_dir = \"data_pse_10fold/data_pse_42_{}\".format(i)\n",
    "        if not os.path.exists(data_dir):\n",
    "            os.makedirs(data_dir)\n",
    "        dev_index=list(K_fold[i])\n",
    "        train_df.iloc[dev_index].to_csv((data_dir+\"/train.csv\").format(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number: 735\n",
      "Number: 735\n",
      "Number: 735\n",
      "Number: 735\n",
      "Number: 735\n",
      "Number: 735\n",
      "Number: 735\n",
      "Number: 735\n",
      "Number: 735\n",
      "Number: 741\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n"
     ]
    }
   ],
   "source": [
    "split_train(test_df, pse_label_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 伪标签和原训练集拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "def pse_merge_train(train_id, pse_id):\n",
    "#     train_id, pse_id = 3,3\n",
    "    train_dir = \"data_StratifiedKFold_42/data_origin_{}/\".format(train_id)\n",
    "    pse_dir = \"data_pse_10fold/data_pse_42_{}/\".format(pse_id)\n",
    "    train_pse_dir = \"origin_data_pse/origin_data_train{}_pse{}/\".format(train_id,pse_id)\n",
    "    os.system(\"cp -r \"+train_dir+\" \"+train_pse_dir)\n",
    "\n",
    "    train_df = pd.read_csv(train_dir+'train.csv')\n",
    "    pse_df = pd.read_csv(pse_dir+'train.csv')\n",
    "\n",
    "    rst = pd.concat([train_df, pse_df],ignore_index=True)\n",
    "    rst.loc[:,['id','title','content','label']].to_csv(train_pse_dir + \"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst = pse_merge_train(3, 3)\n",
    "rst = pse_merge_train(0, 0)\n",
    "rst = pse_merge_train(1, 1)\n",
    "rst = pse_merge_train(2, 2)\n",
    "rst = pse_merge_train(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
